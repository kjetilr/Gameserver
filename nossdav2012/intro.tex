\section{Introduction}

%Over the last decade, online multi-player gaming has experienced an
%amazing growth. Providers of the popular online games must deliver a
%reliable service to thousands of concurrent players meeting strict
%processing deadlines in order for the players to have an acceptable
%quality of experience (QoE). 

%% Game types and server architectures
%% Game server architecture models.
%% -FPS, RTS and small, local servers with low pings.
%% -Separated gameworld instances, each with < 1000 players
%% -Shards, grids and area of interest.

%% Game designs that allow thousands of players to interact in a small
%% space is also challenging.

One major goal for large game providers is to support as many
concurrent players in a game-world as possible while preserving the
strict latency requirements in order for the players to have an
acceptable quality of experience (QoE). In order to achieve this,
game-worlds are typically partitioned into areas-of-interest to
minimize message passing between players with no interaction and to
allow the game-world to be divided between servers. This approach is
however limited by the distribution of players in the game-world, and
the problem is that the distribution of players is heavy-tailed with
about 30\% of players in 1\% of the game area~\cite{chen-2006}. 

In such scenarios, the important metric for online multi-player games
is latency. Claypool et. al.~\cite{claypool++-2006} classify different
types of games and conclude that for first person shooter (FPS) and
racing games, the threshold for an acceptable latency is 100ms. For
other classes of networked games, like real-time strategy (RTS) and
massively multi-player online games (MMOGs) players will tolerate
somewhat higher delays, but there are still strict latency
requirements in order to provide a good QoE. The accumulated latency
of network transmission, server processing and client processing adds
up to the latencies that the user is experiencing, and reducing any of
these latencies will improve the user's experience.

%There is a prevailing belief in the need for single threaded execution
%of the game event loop in order to preserve what is seen as critical
%dependencies in the game~\cite{Abdelkhalek2004++} \PH{Har vi noen
%  eksempler her som bruker dette??}. Due to this
%constriction, even when provisioning for scalability in designing an
%online game, service providers still find that the processing power on
%the server side is becoming scarce~\cite{Cai2002++}.
%\PH{Kan vi omformulere dette? \cite{Cai2002++} er eldre enn %~\cite{Abdelkhalek2004++}}
The traditional design of massively multi-player game servers rely \textit{sharding} for scalability beyond what a single CPU core can handle. \textit{Sharding} involves making a new copy of an area of a game, where players in different copies are unable to interact. This approach eliminates most requirements for communication between the processes running individual shards. An example of such a design can be found in~\cite{chu-2008}.

The industry is now experimenting with
implementations that allow for a greater level of
parallelization. One known example is Eve Online \cite{drain-2008}. With LEARS, we
take this approach even further and focus on how many players can be
handled in a single segment of the game world. We present a model that
allows for better resource utilization of multi-processor, game server
systems which should not replace spatial partitioning techniques for
work distribution, but rather complement them to improve on their
limitations. Furthermore, a real prototype game is used for evaluation
where captured traces are used to generate server load. We compare
multi-threaded and single-threaded implementations in order to measure
the overhead of parallelizing the implementation and showing the
experienced benefits of parallelization. The change in responsiveness
of different implementations with increased load on the server is
studied, and we discuss generic elements of this game design which
impact of our chosen platform of implementation.

Our results indicate that it is possible to design an ``embarrassingly
parallel'' game server. We also observe that the implementation is
able to handle a quadratic increase of in-server communication when
many players interact in a game-world hotspot.

